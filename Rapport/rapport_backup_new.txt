\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[french]{babel}

\begin{document}

\setlength{\marginparwidth}{0pt}
\setlength{\marginparsep}{0pt}

\pagestyle{fancy}
\renewcommand\headrulewidth{1pt}
\fancyhead[L]{\includegraphics[scale=0.22]{logo_uvsq.jpeg}}
\fancyhead[R]{22 décembre 2023}

\hspace{10cm}

\begin{center}
        
    \huge
    Projet de Programmation Numérique
    \vspace{2.0cm}

    \huge 
    \textbf {ARRONDI STOCHASTIQUE POUR LE CALCUL SCIENTIFIQUE} \\

    \vspace{1.0cm}

    \normalsize
    Par Lisa Taldir, Yizhi Yang, Chun Qi, Yutai Zhao \\ Sous l'encadrement de Pablo Oliveira, El Medhi El Arar et Devan Sohier \\ 
       
\end{center}
    
\vspace{1cm}

\tableofcontents

\newpage

\section{Introduction}

Alors que les supercalculateurs sont en essor, permettant des calculs de plus en plus rapides, la question de la précision de ces calculs, bien que moins mise en lumière, est aussi au cœur des recherches. En effet, depuis une dizaine d'années, l'arrondi stochastique commence à devenir plus populaire, notamment grâce à son utilisation pour le machine learning.
\\


L'arrondi stochastique a été introduit pour la première fois par Barnes, Cooke-Yarborough et Thomas (1951), Forsythe (1959), ainsi que Hull et Swenson (1966). C'est un arrondi souvent utilisé dans le domaine du calcul numérique, par exemple pour trouver des solutions d'EDO et d'EDP, valider des méthodes numériques à travers d'une approche empirique. Récemment, il est également appliqué dans le domaine de l'entraînement d'un réseau neuronal (Neural Network Training) [3] et de la mécanique quantique. La plupart des machines ne supportent pas encore l'arrondi stochastique ; cependant, il est introduit dans quelques processeurs particuliers comme Graphecore et la puce neuromorphique d'Intel, Loihi [5].
\\


Dans ce rapport, nous utiliserons l'outil vérificarlo [7] pour calculer l'arrondi stochastique et nous comparerons ses résultats avec ceux de l'arrondi déterministe au plus près, pour différents algorithmes d'exponentiation : une version naïve et une version rapide. Ensuite, nous discuterons de ses avantages et de ses limites.

\subsection{Arrondi déterministe au plus près}

L'IEEE 754 est un standard qui définit le format de la représentation des nombres flottants sous forme binaire. il spécifie en plus les règles pour les opérations arithmétiques en gérant par exemple les arrondis pendant les opérations, afin de garantir une certaine précision du résultat qui ne peut pas être représenté de manière exacte.
\\


L’arrondi déterministe au plus près est l'une des méthodes d'arrondi spécifiées par ce standard, il choisit le flottant représentable le plus proche du résultat. Par exemple, le nombre 0.56 se voit arrondi à 0.6. C'est aussi l'arrondi choisit par défaut sur la majorité des processeurs.

\subsection{Arrondi stochastique}

L'arrondi stochastique, quant à lui, au lieu d'arrondir toujours vers le haut ou vers le bas selon des règles déterministes, utilise une approche probabiliste où la décision d'arrondir est prise avec une certaine probabilité.
\\


Le principe est le suivant : soit x la valeur exacte et fl(x) sa valeur approchée, on pose fl(x) = $\lfloor x \rfloor$ avec une probabilité de p et $\lceil x \rceil$ avec une probabilité de 1-p où \\ p = $\frac{\lceil x \rceil - x}{\lceil x \rceil - \lfloor x \rfloor}$.
Il est alors intéressant de remarquer que 
\begin{center}
    $\mathbb{E}[fl(x)]$ = $\lfloor x \rfloor \times p$ + $\lceil x \rceil \times (1-p)$ = $x$
\end{center}
\\
Ainsi, cet arrondi permet en moyenne de retomber sur la valeur exacte x.\\

\textbf{Nous noterons dans la suite x la valeur exacte et fl(x) la valeur flottante après l'arrondi.}

\section{Étude de l'algorithme d'exponentiation}

Dans cette partie, nous donnerons un pseudo code des algorithmes naïf et rapide et nous étudierons les erreurs d'arrondis théoriques commises lors du calcul de $x^n$ pour chacun de ces algorithmes. Enfin, nous considérerons que $\text{fl}(x \circ y) = (x \circ y)(1 + \delta) $, où \(|\delta| \leq u = 2^{-53}\) désigne l'erreur d'arrondi et nous supposerons que les $\delta_i$ sont indépendants.

\subsection{Algorithme naïf}

Ce qu'on appelle l'exponentiation naïve est l'algorithme implémenté ci dessous :

\begin{algorithm}
\caption{Calcul naïf de $x^n$}
\begin{algorithmic}[1]
    \State $resultat \gets 1$   
    \For{$i=1, n$}
        \State $resultat \gets resultat \times x$
    \EndFor
    \State \textbf{Retourner} $resultat$
\end{algorithmic}
\end{algorithm}

Montrons que pour cet algorithme, on a $\mathbb{E}[fl(x^{n})] = x^{n}$ pour tout $n \in \mathbb{N}$. \\
\newline Tout d'abord, si on note $S_i$ le résultat de $x^{i}$ et $\hat{S}_i$ le résultat de $\text{fl}(x^{i})$, on a :
\begin{flalign*}
    &\hspace{2em} S_{1} = x & \\
    &\hspace{2em} S_{2} = S_{1} \cdot x & \\
    &\hspace{2em} S_{n} = S_{n-1} \cdot x &
\end{flalign*}
Ainsi, on a :
\begin{flalign*}
    &\hspace{2em} \hat{S}_{1} = x & \\
    &\hspace{2em} \hat{S}_{2} = S_{1} \cdot x \cdot (1 + \delta_{1}) & \\
    &\hspace{2em} \hat{S}_{n} = S_{n-1} \cdot x \cdot (1 + \delta_{n-1}) &
\end{flalign*}
Et donc on trouve que $\text{fl}(x^{n}) = x^n \cdot \prod_{i=1}^{n-1}(1+ \delta_i)$. Calculons maintenant son espérance : 
\\
\begin{align*}
    \mathbb{E}[\text{fl}(x^n)] &= \mathbb{E}[x^n \times \prod_{i=1}^{n-1}(1+ \delta_i)] \\
    &= x^n \times \mathbb{E}[\prod_{i=1}^{n-1}(1+ \delta_i)] & \text{comme $x^{n}$ est une constante} \\
    &= x^n \cdot \prod_{i=1}^{n-1} \mathbb{E}[(1+\delta_i)] & \text{par indépendance des $\delta_i$} \\
    &= x^n \cdot \prod_{i=1}^{n-1} (\mathbb{E}[1]+\mathbb{E}[\delta_i]) & \text{par linéarité de l'espérance}\\
    &= x^n \cdot \prod_{i=1}^{n-1} (1+0) \\
    &= x^n
\end{align*}

On obtient donc bien le résultat attendu.
\\

Avant de passer à la démonstration de l'algorithme rapide, montrons que l'on a bien $ \mathbb{E}[\delta_i] = 0$. En effet, supposons que l'on ait $\text{fl}(x) = x \times (1 + \delta)$, 
alors on a $\delta = \frac{\text{fl}(x)}{x} - 1$. 
Et donc comme on a vu que $\mathbb{E}[\text{fl}(x)] = x$, on trouve que
$\mathbb{E}[\delta] = \mathbb{E}[\frac{\text{fl}(x)}{x} - 1] = \frac{1}{x}\mathbb{E}[\text{fl}(x)] - 1 = 0$. \\
\newline Cela permet de conclure notre démonstration. 

\subsection{Algorithme rapide}

Ce qu'on appelle l'exponentiation rapide est l'algorithme décrit ci-dessous :

\begin{algorithm}
\caption{Calcul rapide de $x^n$}
\begin{algorithmic}[2]
    \State $resultat \gets 1$
    \While{$n > 0$}
        \If{$n$ est impair}
            \State $resultat \gets resultat \times x$
        \EndIf
        \State $x \gets x \times x$
        \State $n \gets \lfloor n/2 \rfloor$
    \EndWhile
    \State \textbf{Retourner} $resultat$
\end{algorithmic}
\end{algorithm}


Décomposons l'exposant $n$ en base 2 et stockons chaque bit $a_{i}$. Nous avons ainsi :
\[
  n = 2^{k}a_{k} + 2^{k-1}a_{k-1} + \ldots + 2a_{1}+ a_{0} = \sum_{i=0}^{k} 2^{i}a_i
\]
où $k = 0, \ldots, \lfloor \log_{2}(n) \rfloor$ et $a_i \in \{0,1\}$ pour tout $i \in [0, k]$.
\\
\\
Posons ensuite la somme $U_j = \sum_{i=j+1}^{k} 2^{i}a_i$ et $r = \sum_{i=0}^{k} a_i$.
\\
\\
Nous pouvons remarquer que : 
$$fl(x^n) = x^n \cdot \prod_{j=1}^{n-1} (1+\delta_j)^{U_j} \cdot \prod_{j=n}^{n+r-1} (1+\delta_j) $$
Calculons son espérance : 
$$\mathbb{E}[fl(x^{n})] = \mathbb{E}[x^n \cdot \prod_{i=1}^{n-1} (1+\delta_i)^{U_i} \cdot \prod_{i=n}^{n+r-1} (1+\delta_i)] $$
Par linéarité de l'espérance : 
\begin{align*}
\mathbb{E}[fl(x^{n})] &= x^n \cdot \mathbb{E}[ \prod_{i=1}^{n-1} (1+\delta_i)^{U_i} \cdot \prod_{i=n}^{n+r-1} (1+\delta_i)]\\
&= x^n \cdot \mathbb{E}\left[\prod_{i=1}^{n-1} (1+\delta_i)^{U_i}\right] \cdot \mathbb{E}\left[\prod_{i=n}^{n+r-1} (1+\delta_i)\right] \\
&= x^n \cdot \prod_{i=1}^{n-1} \mathbb{E}[(1+\delta_i)^{U_i}] \cdot \prod_{i=n}^{n+r-1} \mathbb{E}[1+\delta_i]\\
&= x^n \cdot \prod_{i=1}^{n-1} \mathbb{E}[(1+\delta_i)^{U_i}] \cdot 1 \quad \\
&= x^n \cdot \prod_{i=1}^{n-1} \mathbb{E}[(1+\delta_i)^{U_i}]
\end{align*}
\\

Ainsi, on remarque pour l'algorithme d'exponentiation rapide, on ne retombe pas sur la valeur exacte. Cependant, comme $\prod_{i=1}^{n-1} \mathbb{E}[(1+\delta_i)^{U_i}]$ est très proche de 1, le biais est faible.

\section{Implémentation et graphiques obtenus}

Tous les résultats et les fonctions implémentées donc nous allons parler sont accessibles sur GitHub via le lien suivant : 
\begin{center}
    https://github.com/lisataldir/Projet
\end{center}

\subsection{Tests unitaires}
Tout au début de l'implémentation, on lance des tests unitaires pour chaque algorithme : méthodes naïves récursives/itératives et rapides récursives/itératives.

\newpage 

Au lieu de choisir la fonction test d'égalité :

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\begin{lstlisting}[language=C++]
EXPECT_EQ(expected_value, actual_value);
\end{lstlisting}
\\


On applique une autre fonction de Google Test qui est la suivante :

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\begin{lstlisting}[language=C++]
EXPECT_NEAR(actual_value, expected_value, tolerance);
\end{lstlisting}
\\


On prévoit bien une inégalité de la valeur obtenue par nos algorithmes et celle de référence, car c'est exactement les erreurs d'arrondi auxquelles on s'intéresse.
\\

Ici, on définit un taux de tolérance $r = 1.0 \times 10^{-13}$ pour comparer si les deux valeurs obtenues de notre algorithme et de Python sont assez proches l'une et l'autre, c'est-à-dire l'erreur relative ne dépasse jamais ce taux de tolérance $r$. 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{lstlisting}[language=C++, caption=Unit test (extract)]
double r = 1.0E-13;
TEST(ExpNaifRec, BasicTest) 
{
    EXPECT_NEAR(exp_naif_rec(18.9, 6), 45579633.110361, 45579633.110361 * r); 
    EXPECT_NEAR(exp_naif_rec(18.9, 50), 6.6541135651775104E+63, 6.6541135651775104E+63 * r);
    EXPECT_NEAR(exp_naif_rec(18.9, 100), 4.4277227338279358E+127, 4.4277227338279358E+127 * r);

    EXPECT_NEAR(exp_naif_rec(111.11, 8), 23228714744613045.0, 23228714744613045.0 * r);

    EXPECT_NEAR(exp_naif_rec(6543.2, 32), 1.2743427304864022E+122, 1.2743427304864022E+122 * r);
}
\end{lstlisting}

Afin d'améliorer la couverture de test, on parcourt les quatre méthodes par groupes de valeurs à tester; dans chaque groupe, on fixe d'abord une petite base et modifie l'exposant de petite valeur à grande valeur. Ensuite, on répète le même processus en augmentant la base tout juste avant d'atteindre la capacité limite de calcul (où on constate une valeur infinie).
\\


Les tests réussissent car aucune erreur relative dépasse le taux de tolérance. Cela signifie que nos algorithmes sont validés au sens de mathématiques.
\\

On s'intéresse maintenant à l'étude des erreurs d'arrondi.

\subsection{Protocole expérimental}

Pour réaliser les mesures qui vont suivre, un premier calcul de $x^{n}$ en double précision a été réalisé pour $x = 3.995$ et $x = 1.34907566301$. Ensuite, un deuxième calcul en simple précision pour les mêmes valeurs de $x$ a été réalisé pour récupérer les valeurs de l'arrondi déterministe au plus près, afin de comparer ces résultats avec les résultats de l'arrondi stochastique.
\\

Comme l'arrondi stochastique se base sur une probabilité, dix calculs de $x^{n}$ ont été réalisés en simple précision avec verificarlo. On a calculé l'erreur pour chacun de ces calculs puis on a extrait la moyenne des valeurs obtenues ainsi l'écart type.
\\


Enfin, l'erreur a été calculé selon la formule suivante : $ \frac{\| x - \hat{x} \|}{\|x\|}$ (erreur relative).

\subsection{Algorithme naif}

Tout d'abord, la version naïve de l'algorithme d'exponentiation a été implémentée comme ceci :

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{lstlisting}[language=C, caption=Exponentiation naif recursif]
double exp_rapid_iter(double x, int n)
{
    if(n == 0) {
        return 1;
    }
    return x*exp_naif_recursif(x, n-1);
}
\end{lstlisting}

\begin{lstlisting}[language=C, caption=Exponentiation naif iteratif]
double exp_rapid_iter(double x, int n)
{
    double r = 1;
    for(int i = 0; i < n; i++){
        r = r*x;
    }
    return r;
}
\end{lstlisting}

Ces deux implémentions ont la même complexité arithmétique et elles donnent le même résultat, nous les analysons donc ensemble.

\\


Passons maintenant à l'étude des erreurs relatives, où nous commencerons par montrer les erreurs avec l'arrondi déterministe puis avec l'arrondi stochastique. Les mesures ont été réalisées sous x86\_64, avec gcc 11.4.0 pour les mesures de références et pour les calculs avec l'arrondi déterministe, et avec vérificarlo 1.0.0 pour les calculs avec l'arrondi stochastique. Ci-dessous les résultats :

\begin{figure}[!h]
  \centering
  \subfloat[Naïve itérative]{\includegraphics[width=0.5\textwidth]{plot_UR_x_rand_log.png}}
  \subfloat[Naïve récursive]{\includegraphics[width=0.5\textwidth]{plot_UR_x_rand_log_rec.png}}
  \caption{Calcul de l'erreur relative avec l'arrondi déterministe au plus près pour x=1.34907566301}
\end{figure}

\begin{figure}[!h]
  \centering
  \subfloat[Naïve itérative]{\includegraphics[width=0.5\textwidth]{plot_SR_x_rand_log.png}}
  \subfloat[Naïve récursive]{\includegraphics[width=0.5\textwidth]{plot_SR_x_rand_log_rec.png}}
  \caption{Calcul de l'erreur relative avec l'arrondi stochastique pour x=1.34907566301}
\end{figure}

\newpage

\begin{figure}[!h]
  \centering
  \subfloat[Naïve itérative]{\includegraphics[width=0.5\textwidth]{plot_UR_x_3_995_log.png}}
  \subfloat[Naïve récursive]{\includegraphics[width=0.5\textwidth]{plot_UR_x_3_995_log_rec.png}}
  \caption{Calcul de l'erreur relative avec l'arrondi déterministe au plus près pour x=3.995}
\end{figure}

\begin{figure}[!h]
  \centering
  \subfloat[Naïve itérative]{\includegraphics[width=0.5\textwidth]{plot_SR_x_3_995_log.png}}
  \subfloat[Naïve récursive]{\includegraphics[width=0.5\textwidth]{plot_SR_x_3_995_log_rec.png}}
  \caption{Calcul de l'erreur relative avec l'arrondi stochastique pour x=3.995}
\end{figure}

\newpage

On constate que pour les bases différentes (ici $x=1.34907566301$ et $x=3.995$), les erreurs relatives de l'arrondi stochastique et de l'arrondi déterministe ont un ordre de grandeur entre $10^{-7}$ et $10^{-6}$. Cela est raisonnable car la précision simple donne $2^{-23}\approx1.19\times10^{-7}$ chiffres significatifs. 
\\


On observe aussi que l'évolution de l'erreur pour l'arrondi stochastique semble être proche de $O(\sqrt{n}).$ Si l'on compare l'arrondi déterministe avec l'arrondi stochastique, on constate qu'il n'y a pas une grosse différence entre nos deux graphes, quelque soit l'implémention de l'algorithme choisi où le $x$ de départ. Cependant, on sait que les bornes obtenues avec l’arrondi déterministe sont au mieux en $O(n)$, contrairement à celles de l'arrondi stochastique qui arrivent à s'approcher de $O(\sqrt{n}).$ Il serait donc intéressant de faire un nouveau calcul d'erreur avec plus de chiffres significatifs et un n plus grand afin d'avoir une différence plus marquée.
\\

Enfin, en particulier pour $x = 1.34907566301$ on peut voir que l'écart type obtenu avec l'arrondi stochastique est assez conséquent et pour cause en allant regarder les valeurs des erreurs en détail, il est possible de voir une erreur de $10^{-6}$ pour $n=50$ puis de ne plus avoir d'erreur à l'itération suivante, c'est pour cela qu'il est important d'avoir réalisé plusieurs mesures.
\\



\subsection{Algorithme rapide}

Afin de réaliser $y=x^n$, on pourra aussi utiliser la méthode rapide : au lieu de multiplier chaque fois un $x$, on a envie de multiplier deux termes de $x^{n/2}$ (si $n$ pair), ou deux termes de $x^{{(n-1)}/2}$ puis $x$ (si $n$ impair).

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{lstlisting}[language=C, caption=Rapide reccursive]
double exp_rapid_rec(double x, int n)
{
    double r = 0;
    if(n == 0)
        r = 1;
    else if(n == 1)
        r = x;
    else if(n % 2 == 0)
        r = exp_rapid_rec(x, n/2) * exp_rapid_rec(x, n/2);
    else
        r = x * exp_rapid_rec(x, n/2) * exp_rapid_rec(x, n/2);
    return r;
}
\end{lstlisting}

\begin{lstlisting}[language=C, caption=Rapide iterative]
double exp_rapid_iter(double x, int n){
    double r=1;
    while(n!=0){ 
        if((n&1)==1){ //n%2 == 1
            r = r*x;
        }
        x =x*x;
        n = n >> 1; //n = n/2
    }
    return r;
}
\end{lstlisting}
\\

La complexité des méthodes rapides est réduite en \(O(\log n)\), elles sont beaucoup plus rapides lors d'un grand $n$, mais donnent-elles les résultats plus fiables aussi ?  
\\


On applique le même principe pour les méthodes rapides que pour les méthodes naïves. Les mesures de l'arrondi usuel sont réalisées sous x86\_64-apple-darwin21.6.0, avec compilateur Apple clang version 14.0.0 (clang-1400.0.29.202), celles de l'arrondi stochastique sont réalisées aussi avec verificarlo 1.0.0.
\\


Dans un premier temps, on fixe $x=1.11$, $n$ allant de $0$ jusqu'à $6801$. Traçons d'abord une courbe des erreurs absolues, en fixant l'axe des coordonnées en logarithme de base $10$, cela donne une droite. 

\begin{figure}[!h]
  \centering
  \subfloat[Rapide itérative]{\includegraphics[width=0.4\textwidth]{UR_rap_iter_1.11_log.png}\label{fig:UR_rap_iter_1.11}}
  \subfloat[Rapide récursive]{\includegraphics[width=0.4\textwidth]{UR_rap_rec_1.11_log.png}\label{fig:UR_rap_rec_1.11}}
  \caption{Arrondi usuel}
  \label{fig:UR_1.11}
\end{figure}

\begin{figure}[!h]
  \centering
  \subfloat[Rapide itérative]{\includegraphics[width=0.4\textwidth]{SR_rap_iter_1.11_log.png}\label{fig:SR_rap_iter_1.11}}
  \subfloat[Rapide récursive]{\includegraphics[width=0.4\textwidth]{SR_rap_rec_1.11_log.png}\label{fig:SR_rap_rec_1.11}}
  \caption{Arrondi stochastique}
  \label{fig:SR_1.11}
\end{figure}

\newpage

\section{Evaluation de performance}

Nous nous intéressons enfin à savoir si les versions rapides sont vraiment plus "rapides" que les versions de base.\\

Pour ce faire, nous avons teste les 4 algorithmes en calculant 33 fois $x^n$ avec $x$ généré de manière aléatoire à chaque fois et $n = 10$. Chaque calcul est répété r =10000 fois pour pouvoir mesurer la latence en nanoseconde.\\

La latence moyenne est mesurée de la manière suivante : d'abord nous divisons la latence d'un calcul de r répétitions par r, puis nous la stockons dans un tableau contenant toutes les latences de 33 calculs, enfin nous calculons la moyenne de ces 33 latences qui donne notre latence moyenne, dans la colonne "mean" de Figure 6.\\

Les tests ont d'ailleurs été effectués 101 fois, nous avons trié les résultats et pris le résultat "médiane", à savoir le 51ème résultat, comme notre résultat final afin d'éviter des valeurs aberrantes qui ont souvent lieu lors des premiers exécutions.\\


\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[scale=0.15]{exp latence (clang).png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[scale=0.15]{exp latence (gcc).png}
    \end{subfigure}
        \caption{Graphe de performances}
        \label{fig : Graphe de performances}
\end{figure}
\
\
Ignorons les optimisations effectuées par les compilateurs pouvant porter des modifications sur nos codes, telles que la vectorisation et le déroulage de boucle. Nous constatons que avec -O0, malgré les compilateurs utilisés, la version rapide itérative est plus rapide que les versions naïves.
Quant à la version rapide récursive, nous pouvons supposer que sa performance est fortement ralentie par la gestion de la pile. Les informations plus détaillées sont fournies dans Figure 6.\\

\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[scale=0.4]{cclang0.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[scale=0.4]{gcc0.png}
    \end{subfigure}
        \caption{Performances des algorithmes compiles avec Clang -O0 puis GCC -O0}
        \label{fig : Performances avec Clang et GCC -O0}
\end{figure}

Nous savons que lorsqu'une fonction est appelée, une nouvelle "stackframe" est ajoutée à la pile pour stocker les informations locales de cette invocation. Avec les appels récursifs, chaque nouvel appel ajoute une nouvelle stackframe à la pile. Plus la profondeur de la récursion est grande, plus il y a de frames dans la pile.
Ainsi l'empilement et le dépilement des stackframes engendrent un coût de temps supplémentaire.


\newpage

\section{Conclusion}
\\

Après avoir testé les performances avec l'arrondi au plus près, nous nous sommes intéressés à l'impact de l'arrondi stochastique sur les performances de 4 algorithmes. Nous nous demandions si l'arrondi stochastique pourrait influencer les performances, vu que réaliser des arrondis de manière aléatoire demande à priori plus de ressources en termes de logique et de calcul.\\

Un autre problème potentiel c'est que les calculs arrondis par SR sont peu probable d'être reproduits, ainsi nous ne pouvons pas vraiment faire une vérification sur le résultat obtenu par les autres.\\


\section{Références}

\begin{enumerate}
    \item  Kahan, William. “IEEE standard 754 for binary floating-point arithmetic.” Lecture Notes on the Status of IEEE 754.94720-1776 (1996): 11. https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF
    \item What Is Stochastic Rounding?, Nick Higham. https://nhigham.com/2020/07/07/what-is-stochastic-rounding/
    \item Connolly, Michael P., Nicholas J. Higham, and Theo Mary. “Stochastic rounding and its probabilistic backward error analysis.” SIAM Journal on Scientific Computing 43.1 (2021): A566-A585. https://epubs.siam.org/doi/10.1137/20M1334796
    \item Ipsen, Ilse CF, and Hua Zhou. “Probabilistic error analysis for inner products.” SIAM journal on matrix analysis and applications 41.4 (2020): 1726-1741. 
    \newline https://arxiv.org/pdf/1906.10465.pdf
    \item Arar, E. M. E., Sohier, D., de Oliveira Castro, P. et Petit, E. (2022). Stochastic rounding variance and probabilistic bounds: A new approach. arXiv preprint arXiv:2207.10321. 
    https://arxiv.org/abs/2207.10321
    \item El Arar, E. M., Sohier, D., de Oliveira Castro, P. et Petit, E. (2023). Bounds on non-linear errors for variance computation with stochastic rounding. arXiv preprint arXiv:2304.05177. https://arxiv.org/abs/2304.05177
    \item https://github.com/verificarlo/verificarlo
    \item https://fr.wikipedia.org/wiki/IEEE\_754
\end{enumerate}


\end{document}